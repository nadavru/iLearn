<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="Template Mo">
    <link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,500,700,900" rel="stylesheet">

    <title>iLearnML</title>
    <!-- Additional CSS Files -->
    <link rel="stylesheet" type="text/css" href="assets/css/bootstrap.min.css">
    <link rel="stylesheet" type="text/css" href="assets/css/font-awesome.css">
    <link rel="stylesheet" type="text/css" href="assets/css/templatemo-art-factory.css">
    <link rel="stylesheet" type="text/css" href="assets/css/owl-carousel.css">
    <link rel = "icon" href ="assets/images/title_icon.png" type = "image/x-icon">
</head>

<body>

<!-- ***** Preloader Start ***** -->
<div id="preloader">
    <div class="jumper">
        <div></div>
        <div></div>
        <div></div>
    </div>
</div>
<!-- ***** Preloader End ***** -->


<!-- ***** Header Area Start ***** -->
<header class="header-area header-sticky">
    <div class="container">
        <div class="row">
            <div class="col-12">
                <nav class="main-nav">
                    <!-- ***** Logo Start ***** -->
                    <a href="#" class="logo">iLearnML</a>
                    <!-- ***** Logo End ***** -->
                    <!-- ***** Menu Start ***** -->
                    <ul class="nav">
                        <li class="scroll-to-section"><a href="index.html">Home</a></li>
                        <li class="submenu">
                            <a href="playground.html">Playground</a>
                            <ul>
                                <li><a href="playground.html#Func=Gaussian">Gaussian</a></li>
                                <li><a href="playground.html#Func=Beale">Beale</a></li>
                                <li><a href="playground.html#Func=Himmelblau">Himmelblau</a></li>
                                <li><a href="playground.html#Func=Rosenbrock">Rosenbrock</a></li>
                                <li><a href="playground.html#Func=ABS">ABS</a></li>
                                <li><a href="playground.html#Func=Rastrigin">Rastrigin</a></li>
                            </ul>
                        </li>
                        <li class="submenu">
                            <a href="javascript:;">Deep Learning</a>
                            <ul>
                                <li><a href="deepLearning.html">Introduction</a></li>
                            </ul>
                        </li>
                        <li class="submenu">
                            <a href="javascript:;">Optimizations</a>
                            <ul>
                                <li><a href="intro.html">Introduction</a></li>
                                <li><a href="gd.html">Gradient Decent</a></li>
                            </ul>
                        </li>
                        <li class="submenu">
                            <a href="javascript:;">Learning</a>
                            <ul>
                                <li><a href="svm.html">SVM</a></li>
                            </ul>
                        </li>
                    </ul>
                    <a class='menu-trigger'>
                        <span>Menu</span>
                    </a>
                    <!-- ***** Menu End ***** -->
                </nav>
            </div>
        </div>
    </div>
</header>
<!-- ***** Header Area End ***** -->

<div class="section" id="welcome2">

    <!-- ***** Header Text Start ***** -->
    <!-- ***** Header Text End ***** -->
</div>
<!-- ***** Welcome Area End ***** -->


<!-- ***** Features Big Item Start ***** -->

<section id="course2">
    <br>
               <center> <h2>Overview</h2></center>
                <h5>we are now ready to present Gradient Descent (GD) in more detail. GD is the most basic optimization algorithm; most ML-related optimizations rely on some variant of GD. As noted in the previous section, the gradient points in the direction of steepest descent, and thus reversed gradient points in the direction of steepest descent. To illustrate this, run the following demonstration:               </h5>
                <iframe src="https://i-learn-ml.oa.r.appspot.com/Rosenbrock/" width="100%" height="700" scrolling="no"> </iframe>
                <h5>One can easily observe that the arrows in this demo point exactly 'downhill' from wherever we are on the surface – this is the direction of the gradient, and this is we calculated those arrows to for this illustration. </h5>
        <br>
</section>
    <section class="section" id="course">
        <br>
        <br>
        <center><h2>Step size</h2></center>
        <br>

                <h5>
                   So, if we already have an exact mathematical expression of the for direction of steepest descent from current point w_t, why didn't we calculate the expression:
                </h5>
                <img src="assets/images/wt1wt.png">
                <h5>
                    In other words, why don't we simply take 'step size' coefficient of 1? The reason is that the size, rather than merely the direction, of the gradient at out current point may cause us to overshoot the target if we use this expression; it may place us at next stop may not even lead to a decrease in the loss function value.                </h5>
            <img src="assets/images/madness.png">
            <br><h5 style="text-align:center;">Figure 1: step size madness</h5><br> 
            <h5>For example, the wild jumps from one end of the surface to the other we observe figure (1) are only the result of selecting a learning rate of 0.02, not even 1 as we've suggested. Let's reduce the step size dramatically and see what happens:</h5><br> 
            <br>
            <img src="assets/images/tempered.png">
            <br><h5 style="text-align:center;">Figure 2: the better-tempered step size</h5><br> 
            <h5>So how should the step size be selected? So far, we've only discussed constant step size. The index on the step size coefficient suggests that there are methods that calculate the step size every iteration according to certain criteria; we will address that concept later.</h5>
            <h5>One question about the previous that we are still curious about – what does the descent over the loss function looks like on the actual surface of the loss function? The perceptron loss function we presented is a rather poor choice for visual demonstration, so let's solve the same classification problem with a different loss function – linear regression*:</h5>
            <img src="assets/images/lwwt.png">
            <div style="display:inline;">
            <h5>(*) we scaled our data points, to make <img src="assets/images/wtx.png"> for the demonstration.</h5>
            <div>
    </section>
 


<script>
    var changeFunc= function(){
        var url = "https://i-learn-ml.oa.r.appspot.com/";
        var func = document.getElementById('Func').value;
        var ifrm = document.getElementById('ifrm');
        ifrm.src = url+func;
    }

</script>

<!-- jQuery -->
<script src="assets/js/jquery-2.1.0.min.js"></script>

<!-- Bootstrap -->
<script src="assets/js/popper.js"></script>
<script src="assets/js/bootstrap.min.js"></script>

<!-- Plugins -->
<script src="assets/js/owl-carousel.js"></script>
<script src="assets/js/scrollreveal.min.js"></script>
<script src="assets/js/waypoints.min.js"></script>
<script src="assets/js/jquery.counterup.min.js"></script>
<script src="assets/js/imgfix.min.js"></script>

<!-- Global Init -->
<script src="assets/js/custom.js"></script>

</body>
</html>